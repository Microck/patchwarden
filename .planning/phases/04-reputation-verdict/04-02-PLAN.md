---
phase: 04-reputation-verdict
plan: 02
type: execute
wave: 1
depends_on: []
files_modified:
  - src/jarspect/models/verdict.py
  - src/jarspect/agents/verdict_agent.py
  - tests/test_verdict.py
autonomous: true

must_haves:
  truths:
    - "Verdict Agent produces a risk tier and numeric score"
    - "Verdict includes a human-readable explanation with specific indicators"
  artifacts:
    - path: "src/jarspect/agents/verdict_agent.py"
      provides: "Verdict Agent"
    - path: "src/jarspect/models/verdict.py"
      provides: "Verdict models"
  key_links:
    - from: "src/jarspect/agents/verdict_agent.py"
      to: "src/jarspect/models/verdict.py"
      via: "model construction"
      pattern: "Verdict"
---

<objective>
Implement Verdict Agent that synthesizes intake + static + behavior + reputation into a final risk verdict.

Purpose: Produce the product's core output: a risk score + explanation a gamer can act on.
Output: Verdict models + scoring rules + tests.
</objective>

<execution_context>
@/home/ubuntu/.config/opencode/get-shit-done/workflows/execute-plan.md
@/home/ubuntu/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/ROADMAP.md
@.planning/REQUIREMENTS.md
@.planning/phases/03-behavior-analysis/03-03-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Define verdict model and risk tiers</name>
  <files>src/jarspect/models/verdict.py</files>
  <action>
Create `Verdict` model including:
- `risk_tier`: LOW | MEDIUM | HIGH | CRITICAL
- `risk_score`: 0-100
- `summary`: 1-2 sentence headline
- `explanation`: multi-paragraph or bullet list string
- `indicators`: list of structured indicators (source: static/behavior/reputation; id/title; severity; evidence)

This must support "specific suspicious indicators listed" (VERD-04).
  </action>
  <verify>python3 -c "from jarspect.models.verdict import Verdict"</verify>
  <done>Verdict model exists with tiers, score, and indicator list.</done>
</task>

<task type="auto">
  <name>Task 2: Verdict Agent scoring rules + unit tests</name>
  <files>
src/jarspect/agents/verdict_agent.py
tests/test_verdict.py
  </files>
  <action>
Implement deterministic scoring rules (no LLM required for MVP) that combine:
- static severity counts (weighted)
- behavior prediction confidence + risky actions
- reputation score (lower trust increases risk)

Write tests covering:
- benign-ish mod => LOW/MEDIUM
- many high severity patterns + risky behavior => HIGH/CRITICAL
- low reputation pushes a borderline case upward

Ensure the explanation references the triggering indicators (pattern ids, predicted behaviors) rather than generic text.
  </action>
  <verify>python3 -m pytest -q -k verdict --maxfail=1</verify>
  <done>Verdict agent produces stable tier/score and explanation contains specific indicators.</done>
</task>

</tasks>

<verification>
- `python3 -m pytest -q` passes
- Verdict tests cover all tiers at least once
</verification>

<success_criteria>
- Verdict output is clear, specific, and consistent (good for demo)
</success_criteria>

<output>
After completion, create `.planning/phases/04-reputation-verdict/04-02-SUMMARY.md`
</output>
